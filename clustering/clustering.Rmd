---
title: "Clustering"
author: 
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.height=3.5,
                      tidy.opts=list(width.cutoff=60),
                      tidy=TRUE, 
                      warning = FALSE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(imager)
library(formatR)
library(MASS)
```

```{r wrap-hook, echo=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
knitr::opts_chunk$set(linewidth=60)
```

## Movie ratings dataset

```{r}
ratings <- readRDS(file = "data/movieratings.Rds")
str(ratings)
```

```{r, echo = FALSE}
# reshape long to wide
ratings_wide <- ratings %>% 
  dplyr::select(userId, title, rating) %>% 
  pivot_wider(names_from = title, values_from = rating)
```

## Visualising the raw data

```{r, echo = FALSE, fig.height=6}
# visualize the raw data
par(mai = c(2,.5,.5,.5))
image(t(ratings_wide[,-1])[, (nrow(ratings_wide)-1):1], axes = F)
axis(1, at = 0:29/29, names(ratings_wide)[-1], las = 3, cex.axis = 0.7)
axis(2, at = 0:99/99, rownames(ratings_wide), cex.axis = 0.6)
```

## Heatmaps cluster rows and cols

```{r, echo = FALSE, fig.height=6}
heat <- heatmap(as.matrix((ratings_wide[,-1])), 
        scale = "none", margins = c(12, 5))
```

## Manual heatmaps with `image`

```{r,eval=FALSE}
# heatmap
heat <- heatmap(as.matrix((ratings_wide[,-1])), 
        scale = "none", margins = c(12, 5))
row_ordering <- heat$rowInd
col_ordering <- heat$colInd
# reshape long to wide
ratings_wide <- ratings %>% 
  dplyr::select(userId, title, rating) %>% 
  pivot_wider(names_from = title, values_from = rating)
# image wants a matrix of ratings
ratings_mat <- as.matrix(ratings_wide[,-1])
```

```{r,echo=FALSE}
# heatmap
row_ordering <- heat$rowInd
col_ordering <- heat$colInd
# reshape long to wide
ratings_wide <- ratings %>% 
  dplyr::select(userId, title, rating) %>% 
  pivot_wider(names_from = title, values_from = rating)
# image wants a matrix of ratings
ratings_mat <- as.matrix(ratings_wide[,-1])
```

--- 

```{r, fig.height=6}
image(t(ratings_mat[row_ordering, col_ordering]))
```

# Hierarchical clustering

## How does hierarchical clustering work?

```{r, echo=FALSE, fig.height=4, fig.width=4}
x <- data.frame(pt = c(1,2,3,4,5,6),
                x = c(1, 3.5, 3, 7, 7, 9),
                y = c(1, 3.5, 2, 3.5, 8, 8))

x %>% ggplot(aes(x,y)) + geom_point() + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed()
```

## Distance matrix

```{r,echo = FALSE, fig.height=2, fig.width=2}
segs <- data.frame(x = 3.5, y = 3.5, xend = 7, yend = 8)
x %>% ggplot(aes(x,y)) + geom_point() + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  geom_segment(data = segs, aes(x = x, y = y, xend = xend, yend = yend), colour = "red")
```

```{r}
dist(x, method = "euclidean")
```
Smallest distance is between pt 2 and pt 3 (d = 1.87)

## Distance matrix, different metric

```{r,echo = FALSE, fig.height=2, fig.width=2}
segs <- data.frame(x = c(3.5,3.5), y = c(3.5,8), xend = c(3.5,7), yend = c(8,8))
x %>% ggplot(aes(x,y)) + geom_point() + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  geom_segment(data = segs, aes(x = x, y = y, xend = xend, yend = yend), colour = "red")
```

```{r}
dist(x, method = "manhattan")
```

## Standardise variables if scales differ!

```{r}
x2 <- data.frame(var1 = c(10000, 20000, 5000), var2 = c(10,40,20))
dist(x2)
```

```{r}
dist(x2$var1)
```

## Merge pt 2 and 3 into a single cluster

```{r, echo=FALSE, fig.height=4, fig.width=4}
# smallest distance is between pt 2 and pt 3 (d = 1.87)

cols <- c("1" = "red", "2" = "black", "3" = "blue")
          
x$colour1 <- c("2","1","1","2","2","2")

x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour1)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") 
```

## Recalculate distance matrix

```{r, echo=FALSE, fig.height=4, fig.width=4}
# recalculate distance matrix, need to work out distance from each remaining
# point to the cluster we just made 

xfrom <- x[2:3,2:3] 
xto <- x[c(1,4:6), 2:3] %>% rename(xend = x, yend = y)

segs <- cbind(apply(xfrom, 2, rep, times = 4), apply(xto, 2, rep, each = 2)) %>%
  as.data.frame() %>%
  mutate(cols_sl = c("2","1","2","1","2","1","2","1"),
         cols_cl = c("1","2","1","2","1","2","1","2"))

# single linkage (nearest distance)
x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour1)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs[1:2,], aes(x = x, y = y, xend = xend, yend = yend))

```

What is the "distance to a group of points"?

## *Single linkage* 

```{r, echo=FALSE, fig.height=4, fig.width=4}

# single linkage (nearest distance)
x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour1)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs[1:2,], aes(x = x, y = y, xend = xend, yend = yend, colour = cols_sl))

```

... chooses the nearest distance

## *Complete linkage* 

```{r, echo=FALSE, fig.height=4, fig.width=4}
# complete linkage (furthest distance)
x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour1)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs[1:2,], aes(x = x, y = y, xend = xend, yend = yend, colour = cols_cl))

```

... chooses the furthest distance

## *Centroid linkage* 

```{r, echo=FALSE, fig.height=4, fig.width=4}
# centroid linkage (new pt)
cent1 <- data.frame(x = mean(xfrom[,1]), y = mean(xfrom[,2]))
segs_cent <- cbind(apply(cent1, 2, rep, times = 4), apply(xto, 2, rep, each = 1)) %>%
  as.data.frame() %>%
  mutate(cols_sl = c("1","1","1","1"))
  
x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour1)) + 
  geom_point(data = cent1, shape = 2, size = 3, colour = "red") +
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs_cent[1,], aes(x = x, y = y, xend = xend, yend = yend, colour = cols_sl))

```

... uses a new point to represent the cluster

## One more example... 

```{r, echo=FALSE, fig.height=4, fig.width=4}
# single linkage (nearest distance)
x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour1)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs[3:4,], aes(x = x, y = y, xend = xend, yend = yend))
```

## One more example... 

```{r, echo=FALSE, fig.height=4, fig.width=4}
# single linkage (nearest distance)
x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour1)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs[3:4,], aes(x = x, y = y, xend = xend, yend = yend, colour = cols_cl))
```

Single linkage

## One more example... 

```{r, echo=FALSE, fig.height=4, fig.width=4}
# complete linkage (furthest distance)
x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour1)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs[3:4,], aes(x = x, y = y, xend = xend, yend = yend, colour = cols_sl))
```

Complete linkage

## One more example... 

```{r, echo=FALSE, fig.height=4, fig.width=4}
# centroid linkage (new pt)
segs_cent <- cbind(apply(cent1, 2, rep, times = 4), apply(xto, 2, rep, each = 1)) %>%
  as.data.frame() %>%
  mutate(cols_sl = c("1","1","1","1"))

x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour1)) + 
  geom_point(data = cent1, shape = 2, size = 3, colour = "red") +
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs_cent[2,], aes(x = x, y = y, xend = xend, yend = yend, colour = cols_sl))
```

Centroid linkage

## Merge pt 5 and 6 into a single cluster

```{r, echo=FALSE, fig.height=4, fig.width=4}
# join next closest pair of points

x$colour2 <- c("2", "1", "1", "2", "3", '3')

x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour2)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") 
```

## Recalculate distance matrix

```{r, echo=FALSE, fig.height=4, fig.width=4}
# recalculate distance matrix, need to work out distance from each remaining
# point to the cluster we just made 

xfrom <- x[5:6,2:3] 
xto <- x[1:4, 2:3] %>% rename(xend = x, yend = y)

segs <- cbind(apply(xfrom, 2, rep, times = 4), apply(xto, 2, rep, each = 2)) %>%
  as.data.frame() %>%
  mutate(cols_sl = c("2","2","1","2","2","2","2","2"),
         cols_cl = c("2","2","2","2","2","1","2","2"))

# single linkage (nearest distance)
x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour2)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs[3:6,], aes(x = x, y = y, xend = xend, yend = yend))
```

same idea -- need distance between (potentially) two groups of points

## Single linkage

```{r, echo=FALSE, fig.height=4, fig.width=4}
x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour2)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs[3:6,], aes(x = x, y = y, xend = xend, yend = yend, colour = cols_sl))
```

## Complete linkage

```{r, echo=FALSE, fig.height=4, fig.width=4}
x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour2)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs[3:6,], aes(x = x, y = y, xend = xend, yend = yend, colour = cols_cl))
```

## Last step...

```{r, echo=FALSE, fig.height=4, fig.width=4}

x$colour3 <- c("1", "1", "1", "2", "3", '3')

x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour3)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") 

```

## Single linkage

```{r, echo=FALSE, fig.height=4, fig.width=4}
# recalculate distance matrix, need to work out distance from each remaining
# point to the cluster we just made 

xfrom <- x[4,2:3] 
xto <- x[-4, 2:3] %>% rename(xend = x, yend = y)

segs <- cbind(apply(xfrom, 2, rep, times = 5), apply(xto, 2, rep, each = 1)) %>%
  as.data.frame() %>%
  mutate(cols_sl = c("2","1","2","2","2"),
         cols_cl = c("2","2","2","1","2"))

x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour3)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") +
  geom_segment(data = segs[c(2,4),], aes(x = x, y = y, xend = xend, yend = yend, colour = cols_sl))
```

## Final single linkage allocation

```{r, echo=FALSE, fig.height=4, fig.width=4}

x$colour4 <- c("1", "1", "1", "1", "3", '3')

x %>% ggplot(aes(x,y)) + geom_point(aes(colour = colour4)) + 
  lims(x = c(0,10), y = c(0,10)) + coord_fixed() +
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  theme_bw() + theme(legend.position = "none") 
```

## Hierarchical clustering algorithm

1. Each observation starts in its own cluster

2. While number of clusters > 1
+ Merge together the two clusters that are closest to one another
+ Update the distance matrix using one of the linkage rules (single, complete, centroid)

## Hierarchical clustering with `hclust`

```{r, fig.height=4.5}
# single linkage
hcl_single <- dist(ratings_wide[,-1]) %>% hclust(method = "single")
plot(hcl_single)

```

---

```{r, fig.height=4.5}
# complete linkage
hcl_complete <- dist(ratings_wide[,-1]) %>% hclust(method = "complete")
plot(hcl_complete)
```

---
```{r, fig.height=4.5}
# centroid linkage
hcl_centroid <- dist(ratings_wide[,-1]) %>% hclust(method = "centroid")
plot(hcl_centroid)
```

## Where to cut?

```{r, echo=FALSE, fig.height=4.5}
plot(hcl_complete)
```

## Allocate each row to a cluster

```{r}
user_clusters <- cutree(hcl_complete, h = 9)
ratings_wide <- ratings_wide %>% mutate(user_clusters = user_clusters)
table(ratings_wide$user_clusters)
```

Always check cluster sizes

```{r, echo=FALSE}
# for later
user_clusters_df <- data.frame(userId = ratings_wide$userId, 
                               user_clus = user_clusters, row.names = NULL)
```

## Review clusters

```{r, echo = FALSE, fig.height=4.5}
# plot mean movie ratings within each cluster
cluster_means <- ratings_wide %>% 
  group_by(user_clusters) %>%
  summarise_at(vars(-starts_with("user")), mean, na.rm = TRUE) %>% 
  ungroup()

cluster_means %>% mutate(user_clusters = factor(user_clusters)) %>%
  pivot_longer(cols = -1, names_to = "title", values_to = "rating") %>%
  ggplot(aes(x = title, y = rating, colour = user_clusters, group = user_clusters)) + 
  geom_line() + coord_flip() + xlab(element_blank()) + ylab(element_blank())
```

---

```{r, echo = FALSE, fig.height=4.5}
cluster_means %>% mutate(user_clusters = factor(user_clusters)) %>%
  pivot_longer(cols = -1, names_to = "title", values_to = "rating") %>%
  ggplot(aes(x = title, y = rating, colour = user_clusters, group = user_clusters)) +
  facet_grid(. ~ user_clusters) +
  geom_line() + coord_flip() + xlab(element_blank()) + ylab(element_blank())
```

## Redo heatmap after grouping users into clusters

```{r, echo=FALSE, fig.height=4.5}
ratings_userclus <- ratings_wide %>% 
  dplyr::select(-userId) %>% group_by(user_clusters) %>%
  summarise_all(mean, na.rm = TRUE) 
heatmap(as.matrix((ratings_userclus[,-1])), scale = "none", margins = c(12, 5))

```

## ... or keep users separate but reorder

```{r, echo=FALSE, fig.height=6}
hcl_row_ordering <- hcl_complete$order
par(mfrow = c(1,2))
image(t(as.matrix(ratings_mat)), main = "Original Matrix")
image(t(ratings_mat[hcl_row_ordering, ncol(ratings_mat):1]), main = "Reordered rows")
```

# Clustering movies 

## Transpose and repeat...

```{r}
# transpose and leave out Id and cluster memb columns
ratings_wide_t <- t(ratings_wide[,-c(1,32)]) %>% as.data.frame()
# column names should be userId's
names(ratings_wide_t) <- ratings_wide$userId
# complete linkage again (or try others)
hcl_complete <- dist(ratings_wide_t) %>% hclust(method = "complete")
```

---

```{r, echo=FALSE,fig.height=6}
plot(hcl_complete)
```

## Allocate movies to clusters

```{r}
title_clusters <- cutree(hcl_complete, k = 6)
table(title_clusters)
```

```{r, echo=FALSE}
# for later
title_clusters_df <- data.frame(title = names(title_clusters), title_clus = title_clusters, row.names = NULL)
```

---

```{r, linewidth=60}
# movies in cluster 1
str_c(title_clusters_df[title_clusters_df$title_clus == 1, "title"], collapse = "; ")
# movies in cluster 2
str_c(title_clusters_df[title_clusters_df$title_clus == 2, "title"], collapse = "; ")
```

## Review clusters

```{r, echo=FALSE, fig.height=5}
ratings_wide_t <- ratings_wide_t %>% mutate(title_clusters = title_clusters)

ratings_titleclus <- ratings_wide_t %>% group_by(title_clusters) %>%
  summarise_all(mean, na.rm = TRUE) 

# plot mean movie ratings within each cluster
cluster_means <- ratings_wide_t %>% 
  group_by(title_clusters) %>%
  summarise_all(mean, na.rm = TRUE) %>% 
  ungroup()

cluster_means %>% mutate(title_clusters = factor(title_clusters)) %>%
  pivot_longer(cols = -1, names_to = "user", values_to = "rating") %>%
  ggplot(aes(x = user, y = rating, colour = title_clusters, group = title_clusters)) + 
  geom_line() + coord_flip() + xlab(element_blank()) + ylab(element_blank())

```

---

```{r, echo=FALSE, fig.height=6}
cluster_means %>% mutate(title_clusters = factor(title_clusters)) %>%
  pivot_longer(cols = -1, names_to = "user", values_to = "rating") %>%
  ggplot(aes(x = user, y = rating, colour = title_clusters, group = title_clusters)) + 
  geom_line() + coord_flip() + xlab(element_blank()) + ylab(element_blank()) +
  facet_grid(. ~ title_clusters)
```

## Heatmap with movie clusters

```{r, echo=FALSE, fig.height=4.5}
heatmap(as.matrix((ratings_titleclus[,-1])), scale = "none", margins = c(12, 5))
```

## ... or just reordering movies

```{r, echo=FALSE, fig.height=6}
hcl_col_ordering <- hcl_complete$order
par(mfrow = c(1,2))
image(t(as.matrix(ratings_mat)), main = "Original Matrix")
image(t(ratings_mat[nrow(ratings_mat):1, col_ordering]), main = "Reordered columns")
```

# Putting it all together

---

```{r, echo=FALSE}
par(mfrow = c(1,4))
image(t(as.matrix(ratings_mat)), main = "Original Matrix")
image(t(ratings_mat[hcl_row_ordering, ncol(ratings_mat):1]), main = "Reordered rows")
image(t(ratings_mat[nrow(ratings_mat):1, hcl_col_ordering]), main = "Reordered columns")
image(t(ratings_mat[hcl_row_ordering, hcl_col_ordering]), main = "Reordered both")
```

## World's smallest heatmap

```{r, echo=FALSE,fig.height=4.5, message=FALSE, warning=FALSE}
# merge in cluster memberships for users and movies
ratings <- ratings %>% 
  left_join(user_clusters_df, by = "userId") %>% 
  left_join(title_clusters_df, by = "title")

# summarize
ratings_bothclus <- ratings %>% 
  group_by(title_clus, user_clus) %>%
  summarize(rating = mean(rating, na.rm = TRUE)) %>% 
  ungroup() %>% 
  pivot_wider(names_from = title_clus, values_from = rating)

heatmap(as.matrix((ratings_bothclus[,-1])), scale = "none", margins = c(5, 5))
```

# k-means clustering

## How does k-means work?

```{r, echo=FALSE, fig.height=4, fig.width=6}
x <- data.frame(x = c(-5, -1, -2, -0.4, -1.5, 1, 2, 3, 2, 2, 4),
                y = c(-1, -2, 3, 0.4, 2, -1.5, -0.5, -1.5, 0.5, 3, 1.5))

cols <- c("red" = "red", "blue" = "blue")

# plot raw pts
x %>% ggplot(aes(x, y)) + geom_point() + 
  coord_fixed(xlim = c(-6,6), ylim = c(-4,4)) + theme_bw() 
```

## Choose random initial centroids 

```{r, echo=FALSE, fig.height=4, fig.width=6}
# choose random initial centroids
cents <- x[c(1,11), ]
cents$col <- c("red", "blue")
cents <- cents %>% arrange(col)

# plot points with centroids
x %>% ggplot(aes(x, y)) + geom_point() + 
  geom_point(data = cents, aes(colour = col), size = 4, shape = 2) + 
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  coord_fixed(xlim = c(-6,6), ylim = c(-4,4)) +
  theme_bw() + theme(legend.position = "none") 
```

## Allocate points to clusters

Each observation goes to the cluster with the closest centroid

```{r, echo=FALSE, fig.height=4, fig.width=6}
# calculate distance to each centroid
x <- x %>% mutate(dist1 = (x - cents$x[1])^2 + (y - cents$y[1])^2,
                  dist2 = (x - cents$x[2])^2 + (y - cents$y[2])^2,
                  col1 = ifelse(dist1 < dist2, "blue", "red"))
x
```

## Allocate points to clusters

```{r, echo=FALSE, fig.height=4, fig.width=6}
# allocate each obs to nearest cluster
x %>% ggplot(aes(x, y)) + geom_point(aes(colour = col1)) + 
  geom_point(data = cents, aes(colour = col), size = 4, shape = 2) + 
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  coord_fixed(xlim = c(-6,6), ylim = c(-4,4)) +
  theme_bw() + theme(legend.position = "none") 
```

## Recalculate cluster centroids 

```{r, echo=FALSE, fig.height=4, fig.width=6, warning=FALSE, message=FALSE}
# recalculate centroids
cents <- x %>% group_by(col1) %>% summarize(x = mean(x), y = mean(y)) %>%
  rename(col = col1)

# plot points with centroids
x %>% ggplot(aes(x, y)) + geom_point() + 
  geom_point(data = cents, aes(colour = col), size = 4, shape = 2) + 
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  coord_fixed(xlim = c(-6,6), ylim = c(-4,4)) +
  theme_bw() + theme(legend.position = "none") 
```

## Allocate points to clusters

```{r, echo=FALSE, fig.height=4, fig.width=6}
# calculate distance to each centroid
x <- x %>% mutate(dist1 = (x - cents$x[1])^2 + (y - cents$y[1])^2,
                  dist2 = (x - cents$x[2])^2 + (y - cents$y[2])^2,
                  col2 = ifelse(dist1<dist2, "blue", "red"))

# allocate each obs to nearest cluster
x %>% ggplot(aes(x, y)) + geom_point(aes(colour = col2)) + 
  geom_point(data = cents, aes(colour = col), size = 4, shape = 2) + 
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  coord_fixed(xlim = c(-6,6), ylim = c(-4,4)) +
  theme_bw() + theme(legend.position = "none") 
```

## Recalculate cluster centroids 

```{r, echo=FALSE, fig.height=4, fig.width=6}
# recalculate centroids
cents <- x %>% group_by(col2) %>% summarize(x = mean(x), y = mean(y)) %>%
  rename(col = col2)

# plot points with centroids
x %>% ggplot(aes(x, y)) + geom_point() + 
  geom_point(data = cents, aes(colour = col), size = 4, shape = 2) + 
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  coord_fixed(xlim = c(-6,6), ylim = c(-4,4)) +
  theme_bw() + theme(legend.position = "none") 
```

## Allocate points to clusters

```{r, echo=FALSE, fig.height=4, fig.width=6}
# calculate distance to each centroid
x <- x %>% mutate(dist1 = (x - cents$x[1])^2 + (y - cents$y[1])^2,
                  dist2 = (x - cents$x[2])^2 + (y - cents$y[2])^2,
                  col3 = ifelse(dist1<dist2, "blue", "red"))

# allocate each obs to nearest cluster
x %>% ggplot(aes(x, y)) + geom_point(aes(colour = col3)) + 
  geom_point(data = cents, aes(colour = col), size = 4, shape = 2) + 
  scale_discrete_manual(values = cols, aesthetics = "colour") +
  coord_fixed(xlim = c(-6,6), ylim = c(-4,4)) +
  theme_bw() + theme(legend.position = "none") 
```

Continue until no change, or some convergence criterion met

## k-means clustering algorithm

1. Randomly choose *k* initial centroids

2. While some convergence criterion not satisfied
+ Allocate each observation to the cluster whose centroid it is closest to
+ Recalculate cluster centroids
<br><br>
+ A heuristic for minimizing the sum of within-cluster variances
+ Different random starts -> Different clusterings
+ How to choose *k*?

## Choosing *k*

+ "By eye"
+ Plot % variance explained (between-cluster SS / total SS) against *k*
+ Cross validation
    + Partition data into *m* parts. 
    + For each of the *m* parts, 
        + keep that part aside as test data,
        + fit clustering model on the rest of the data, 
        + calculate the sum of the squared distances to the centroids for the test set
    + Choose the value of *k* that gives the best average performance

## Back to the movies

```{r}
df <- ratings_wide %>% dplyr::select_at(vars(-starts_with("user")))
kmeansObj <- kmeans(df, centers = 6)
```
```{r}
names(kmeansObj)
```

--- 

```{r}
kmeansObj$cluster
```

```{r}
kmeansObj$centers[,1:3]
```

## Plotting cluster means

```{r, tidy=FALSE}
# tidy for ggplot
kmm <- kmeansObj$centers %>% as.data.frame() %>% 
  mutate(user_clus_km = paste0("clust",1:6)) %>%
  pivot_longer(-user_clus_km, names_to = "title", values_to = "rating") 
head(kmm)
```

---

```{r, echo=FALSE}
kmm %>%
  ggplot(aes(x = title, y = rating, colour = user_clus_km, group = user_clus_km)) + 
  geom_line() + coord_flip() + xlab(element_blank()) + ylab(element_blank())
```

## similarity between `hclust` and `kmeans`

```{r}
table(user_clusters, kmeansObj$cluster)
```

# Dimension reduction = clustering for variables

## Principle components analysis

+ transforms a set of observations on possibly correlated variables into observations on a set of uncorrelated variables called principal components.
<br><br>
+ transformation is chosen so each principal component has the largest possible variance subject to the constraint that it is orthogonal to any existing components.

## Principle components analysis

+ observation $i$ on original variables $\mathbf{x}_i = (x_{i1},x_{i2},\dots,x_{in})$
<br><br>
+ means for each variable over all observations $\mathbf{m} = (\bar{x}_{1},\bar{x}_{2},\dots,\bar{x}_{n})$
<br><br>
+ PC1: linearly transformed observation $\mathbf{v}_1\mathbf{x}_i = (v_{11}x_{i1},v_{12}x_{i2},\dots,v_{1n}x_{in})$
<br><br>
+ PC2: linearly transformed observation $\mathbf{v}_2\mathbf{x}_i = (v_{21}x_{i1},v_{22}x_{i2},\dots,v_{2n}x_{in})$
<br><br>
+ etc

## Principle components analysis

+ Choose coefficients for PC $j$ $\mathbf{v}_j$ to maximise $$\displaystyle\frac{1}{m-1}\sum_{i=1}^m(\mathbf{v}^T_j\mathbf{x}_i - \mathbf{v}^T_j\mathbf{m})^2$$

subject to the constraint that $\mathbf{v}_j$ is orthogonal to all the previous $\mathbf{v}_j$'s i.e. $\mathbf{v}^T_j\mathbf{v}_k=0$ for $k<j$.

## Geometric interpretation of PCA

```{r, echo=FALSE}
set.seed(123)
```

```{r}
x <- mvrnorm(n = 1000, mu = c(0,0), Sigma = matrix(c(1,0.6,0.6,1), ncol = 2))
plot(x[,1],x[,2], xlim = c(-5,5), ylim = c(-5,5))
```

## Geometric interpretation of PCA

```{r, eval=FALSE}
x <- mvrnorm(n = 1000, mu = c(0,0), Sigma = matrix(c(1,0.6,0.6,1), ncol = 2))
plot(x[,1],x[,2], xlim = c(-5,5), ylim = c(-5,5))
```

```{r, echo=FALSE}
set.seed(123)
```

```{r, echo=FALSE}
x <- mvrnorm(n = 1000, mu = c(0,0), Sigma = matrix(c(1,0.6,0.6,1), ncol = 2))
plot(x[,1],x[,2], xlim = c(-5,5), ylim = c(-5,5))
abline(-3,1, col = "red")
```

## Geometric interpretation of PCA

```{r}
z <- prcomp(x)
plot(z$x[,1], z$x[,2])
```


## Singular value decomposition

+ Decomposes an (m * n) matrix **X** into the product of
    + an (m * m) matrix **U**
    + an (m * n) diagonal matrix **D**
    + an (n * n) matrix **V**
<br><br>
+ **X** = **UDV^T^**
<br><br>
+ Columns of **U** are *left-singular vectors*
+ Columns of **V** are *right-singular vectors*
+ Diagonal elements of **D** are *singular values*

## Dimension reduction = clustering for variables

+ SVD is not unique
<br><br>
+ We choose the decomposition that gives the singular values in descending order (there is only one decomposition like this)
<br><br>
+ PCs are equal to the right SVs if you scale the data to have mean 0 and sd 1

---

```{r}
# don't need to reorder rows and cols, but will make visualizing PCA easier
ratings_scaled_ordered <- scale(ratings_mat)[hcl_row_ordering, hcl_col_ordering]
# do the svd
svd1 <- svd(ratings_scaled_ordered)
# rename svd outputs
u <- svd1$u
v <- svd1$v
d <- diag(svd1$d)
# approximate original data with outer product of first singular vector
approx1 <- u[,1] %*% matrix(d[1,1],nrow=1) %*% t(v[,1])
```

---

```{r,echo=FALSE,fig.height=6}
par(mfrow = c(1, 2))
image(t(ratings_scaled_ordered[100:1,]), main = "Original Matrix")
image(t(approx1)[, nrow(approx1):1], main = "Approximation (1 SV)")
```

---

```{r}
approx2 <- u[,1:2] %*% d[1:2,1:2] %*% t(v[,1:2])
approx5 <- u[,1:5] %*% d[1:5,1:5] %*% t(v[,1:5])
approx30 <- u %*% d %*% t(v)
```

---

```{r,echo=FALSE,fig.height=6}
par(mfrow = c(1, 5))
image(t(ratings_scaled_ordered[100:1,]), main = "Original Matrix")
image(t(approx1)[, nrow(approx1):1], main = "Approximation (1 SV)")
image(t(approx2)[, nrow(approx2):1], main = "Approximation (2 SV)")
image(t(approx5)[, nrow(approx5):1], main = "Approximation (5 SV)")
image(t(approx30)[, nrow(approx30):1], main = "Approximation (30 SV)")
```
 
## How many vectors are needed?

```{r, echo=FALSE, fig.height=6}
par(mfrow=c(1,3))
plot(svd1$d, xlab = "Column", ylab = "Singular value", pch = 19)
plot(svd1$d / sum(svd1$d), xlab = "Column", ylab = "% variance explained", pch = 19)
plot(cumsum(svd1$d) / sum(svd1$d), xlab = "Column", ylab = "Cumulative % variance explained", pch = 19)

```

## SVD vs PCA

PCs are equal to the right SVs if you scale the data to have mean 0 and sd 1

---

```{r, fig.height=4}
ratings_ordered <- ratings_mat[hcl_row_ordering, hcl_col_ordering]
pca1 <- prcomp(ratings_ordered, scale = TRUE)
plot(pca1$rotation[, 1], svd1$v[, 1])
```

---

```{r, echo=FALSE, fig.height=5}
par(mfrow = c(1,2))
plot(svd1$d, xlab = "Column", pch = 19)
plot(pca1$sdev, xlab = "Column", pch = 19)
```

# Image compression with PCA
---

```{r, echo=FALSE}
mona <- load.image("data/lowres_mona.png")
plot(mona)
```

---

```{r}
# transform into matrix form
mona_mat <- as.data.frame(mona) %>% 
  pivot_wider(names_from = y, values_from = value) %>%
  dplyr::select(-x) %>%
  as.matrix()
image(mona_mat[, nrow(mona_mat):1], col = gray.colors(100))
```

---

```{r}
# svd
svd1 <- svd(mona_mat)
u <- svd1$u; v <- svd1$v; d <- diag(svd1$d)

# number of singular values
nsv <- 1
# approximate original data with outer product of first N singular vectors
approx <- u[,1:nsv] %*% matrix(d[1:nsv,1:nsv],nrow=nsv) %*% t(v[,1:nsv])
```

## With 1 SV

```{r, echo=FALSE,fig.height=5}
image(approx[, nrow(approx):1], col = gray.colors(30))
```

## With 2 SV

```{r, echo=FALSE,fig.height=5}
nsv <- 2
approx <- u[,1:nsv] %*% matrix(d[1:nsv,1:nsv],nrow=nsv) %*% t(v[,1:nsv])
image(approx[, nrow(approx):1], col = gray.colors(30))
```

## With 5 SV

```{r, echo=FALSE,fig.height=5}
nsv <- 5
approx <- u[,1:nsv] %*% matrix(d[1:nsv,1:nsv],nrow=nsv) %*% t(v[,1:nsv])
image(approx[, nrow(approx):1], col = gray.colors(30))
```

## With 20 SV

```{r, echo=FALSE,fig.height=5}
nsv <- 20
approx <- u[,1:nsv] %*% matrix(d[1:nsv,1:nsv],nrow=nsv) %*% t(v[,1:nsv])
image(approx[, nrow(approx):1], col = gray.colors(30))
```

## With 50 SV

```{r, echo=FALSE,fig.height=5}
nsv <- 50
approx <- u[,1:nsv] %*% matrix(d[1:nsv,1:nsv],nrow=nsv) %*% t(v[,1:nsv])
image(approx[, nrow(approx):1], col = gray.colors(30))
```

## How many SVs is enough?

```{r, echo=FALSE,fig.height=5}
plot(svd1$d / sum(svd1$d), xlab = "Column", ylab = "% variance explained", pch = 19)
```

